{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from texttable import Texttable\n",
    "\n",
    "from metrics import print_and_analysis_performance_mean_std, print_overall_performance_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaca8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "alpha = 1\n",
    "seeds = [10, 20, 30, 40, 50]\n",
    "upset_choices = ['upset simple', 'upset ratio', 'upset naive']\n",
    "selected_metrics = ['kendall tau'] + upset_choices\n",
    "NUM_UPSET_CHOICES = len(upset_choices)\n",
    "METRICS_NUM = len(selected_metrics)\n",
    "baselines = ['SpringRank','syncRank','serialRank','btl', 'davidScore',\n",
    "        'eigenvectorCentrality', 'PageRank', 'rankCentrality', 'SVD_RS', 'SVD_NRS']\n",
    "GNN_selection_choices = ['lr', 'train with', 'pretrain with', 'upset margin coeff', \\\n",
    "                'trainable alpha', 'baseline', \\\n",
    "                         'upset ratio coeff', 'Fiedler layer num', 'pretrain epochs']\n",
    "GNN_selection_choices_curr = ['lr', 'train with', 'pretrain with', 'upset margin coeff',  \\\n",
    "                 'baseline', 'upset ratio coeff']\n",
    "GNN_CHOICES_NUM = len(GNN_selection_choices)\n",
    "GNN_CHOICES_NUM_CURR = len(GNN_selection_choices_curr)\n",
    "mvr = ['mvr']\n",
    "all_GNNs = ['DIGRAC', 'ib']\n",
    "desirable_list = [1, 2, 5]\n",
    "train_with_list = ['dist', 'innerproduct', 'proximal_dist', 'proximal_innerproduct','proximal_baseline']\n",
    "\n",
    "GNN_variant_names = train_with_list\n",
    "GNN_NUM = 10\n",
    "\n",
    "def generate_method_str_and_compare_names_all(all_methods=baselines):\n",
    "    method_str = ''\n",
    "    for method_name in all_methods:\n",
    "        method_str += method_name\n",
    "    \n",
    "    compare_names_all = []\n",
    "    for method_name in all_methods:\n",
    "        if method_name not in ['DIGRAC', 'ib']:\n",
    "            compare_names_all.append(method_name)\n",
    "        else:\n",
    "            for GNN_type in GNN_variant_names:\n",
    "                compare_names_all.append(method_name+'_'+GNN_type)\n",
    "    return method_str, compare_names_all\n",
    "\n",
    "GNN_NUM = 10\n",
    "GNN_names = []\n",
    "for method_name in ['DIGRAC', 'ib']:\n",
    "    for GNN_type in GNN_variant_names:\n",
    "        GNN_names.append(method_name+GNN_type)\n",
    "\n",
    "non_proximal_ind = [0, 1, 5, 6]\n",
    "proximal_ind = [2, 3, 4, 7, 8, 9]\n",
    "NON_PROXIMAL_GNN_NUM = len(non_proximal_ind)\n",
    "PROXIMAL_GNN_NUM = len(proximal_ind)\n",
    "non_proximal_bool = np.zeros(GNN_NUM, dtype=bool)\n",
    "proximal_bool = np.zeros(GNN_NUM, dtype=bool)\n",
    "for i in non_proximal_ind:\n",
    "    non_proximal_bool[i] = True\n",
    "for i in proximal_ind:\n",
    "    proximal_bool[i] = True\n",
    "\n",
    "GNN_names_non_proximal = ['DIGRAC_dist', 'DIGRAC_innerproduct',\\\n",
    "                          'ib_dist', 'ib_innerproduct']\n",
    "GNN_names_proximal = ['DIGRAC_proximal_dist', 'DIGRAC_proximal_innerproduct', 'DIGRAC_proximal_baseline', \\\n",
    "                      'ib_proximal_dist', 'ib_proximal_innerproduct', 'ib_proximal_baseline']\n",
    "\n",
    "methods_of_interest = ['inductive', 'original']\n",
    "compare_names_all = baselines + mvr + methods_of_interest\n",
    "METHODS_NUM = len(compare_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482cb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['DIGRAC_dist', 'DIGRAC_innerproduct',\\\n",
    "                          'ib_dist', 'ib_innerproduct', \\\n",
    "        'DIGRAC_proximal_dist', 'DIGRAC_proximal_innerproduct', 'DIGRAC_proximal_baseline', \\\n",
    "                      'ib_proximal_dist', 'ib_proximal_innerproduct', 'ib_proximal_baseline', \\\n",
    "       ]\n",
    "values = ['DIGRAC dist', 'DIGRAC innerproduct',\\\n",
    "                          'ib dist', 'ib innerproduct', \\\n",
    "        'DIGRAC proximal dist', 'DIGRAC proximal innerproduct', 'DIGRAC proximal baseline', \\\n",
    "                      'ib proximal dist', 'ib proximal innerproduct', 'ib proximal baseline']\n",
    "\n",
    "keys += train_with_list + ['dist', 'innerproduct', 'serial_similarity'] + \\\n",
    "['avg_football', 'avg_finer_football', 'avg_basketball', 'avg_finer_basketball']\n",
    "values += ['dist', 'innerproduct', 'proximal dist', 'proximal innerproduct','proximal baseline'] + \\\n",
    "['dist', 'innerproduct', 'SerialRank similarity'] + \\\n",
    "['{\\it Football (avg)}', '{\\it Football finer (avg)}', '{\\it Basketball (avg)}', '{\\it Basketball finer (avg)}']\n",
    "name_mapping_dict = dict(zip(keys, values))\n",
    "print(name_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44de28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_save_name(dataset='HeadToHead', all_methods=all_GNNs, K=5, train_with='dist', upset_ratio_coeff=1.0, upset_margin_coeff=0, upset_margin=0.01,\n",
    "                           trainable_alpha=False, lr=0.01, hidden=32, num_trials=10, train_ratio=1, test_ratio=1,  AllTrain=True, rank_baseline='SpringRank', sigma=1.0, \n",
    "                           Fiedler_layer_num=5, pretrain_epochs=50, pretrain_with='dist'):\n",
    "    default_name_base = ''\n",
    "    if 'DIGRAC' in all_methods or 'ib' in all_methods:\n",
    "        default_name_base += 'K' + str(K) + 'dropout' + str(int(100*dropout))\n",
    "        default_name_base += 'ratio_coe' + str(int(100*upset_ratio_coeff)) + 'margin_coe' + str(int(100*upset_margin_coeff)) \n",
    "        if upset_margin_coeff > 0:\n",
    "            default_name_base += 'margin' + str(int(100*upset_margin)) \n",
    "        default_name_base += 'with' + str(train_with)  + 'Fiedler' + str(Fiedler_layer_num) + 'sigma' + str(int(100*sigma))\n",
    "        default_name_base += 'alpha' + str(int(100*alpha))\n",
    "        if train_with[:8] == 'proximal':\n",
    "            default_name_base += 'train_alpha' + str(trainable_alpha)\n",
    "        default_name_base += 'hid' + str(hidden) + 'lr' + str(int(1000*lr))\n",
    "        default_name_base += 'use' + str(rank_baseline)\n",
    "        if pretrain_epochs > 0 and train_with[:8] == 'proximal':\n",
    "            default_name_base +=  'pre' + str(pretrain_with) + str(int(pretrain_epochs))\n",
    "    save_name_base = default_name_base\n",
    "\n",
    "    default_name_base +=  'trials' + str(num_trials) + 'train_r' + str(int(100*train_ratio)) + 'test_r' + str(int(100*test_ratio)) + 'All' + str(AllTrain)\n",
    "    if dataset[:3] == 'ERO':\n",
    "        default_name_base += 'seeds' + '_'.join([str(value) for value in np.array(seeds).flatten()])\n",
    "    return default_name_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_and_K(dataset, season=2009, K=5, p=0.05, ERO_style='uniform', eta=0.1, N=350):\n",
    "    F_style = 'path'\n",
    "    sp_style = 'random'\n",
    "    ambient = 0\n",
    "    if dataset[-1]!='/':\n",
    "        dataset += '/'\n",
    "\n",
    "    if dataset[:3] == 'ERO':\n",
    "        hidden = 8\n",
    "        K = 5\n",
    "        F = 3\n",
    "        default_name_base = 'p' + str(int(100*p)) + 'K' + str(K) + 'N' + str(N)\n",
    "        default_name_base += 'eta' + str(int(100*eta)) + 'style' + str(ERO_style)\n",
    "        dataset = 'ERO/' + default_name_base\n",
    "        dataset_print = 'ERO(p={}, style={},$\\eta$={})'.format(p, ERO_style, eta)\n",
    "    elif dataset[:10].lower() == 'basketball':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 70\n",
    "        K = 20\n",
    "        dataset = 'Basketball_temporal/' + str(season)\n",
    "        dataset_print = 'Basketball({})'.format(season)\n",
    "    elif dataset[:16].lower() == 'finer_basketball':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 2\n",
    "        K = 20\n",
    "        dataset = 'Basketball_temporal/finer' + str(season)\n",
    "        dataset_print = 'Basketball finer({})'.format(season)\n",
    "    elif dataset[:6].lower() == 'animal':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 3\n",
    "        K = 3\n",
    "        dataset = 'Dryad_animal_society/'\n",
    "        dataset_print = 'Animal'\n",
    "    elif dataset[:7].lower() == 'finance':\n",
    "        hidden = 32\n",
    "        hidden_compare = 32\n",
    "        F = 5 # threshold: > 0.7, others have threshold > 0.9\n",
    "        K = 20\n",
    "        dataset_print = 'Finance'\n",
    "    elif dataset[:10].lower() == 'headtohead':\n",
    "        hidden = 16\n",
    "        hidden_compare = 16\n",
    "        F = 39\n",
    "        K = 48\n",
    "        dataset = 'Halo2BetaData/HeadToHead'\n",
    "        dataset_print = 'HeadToHead'\n",
    "    elif dataset[:16].lower() == 'faculty_business':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 6\n",
    "        K = 5\n",
    "        dataset = 'FacultyHiringNetworks/Business/Business_FM_Full_'\n",
    "        dataset_print = 'Faculty: Business'\n",
    "    elif dataset[:10].lower() == 'faculty_cs':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 8\n",
    "        K = 9\n",
    "        dataset = 'FacultyHiringNetworks/ComputerScience/ComputerScience_FM_Full_'\n",
    "        dataset_print = 'Faculty: CS'\n",
    "    elif dataset[:15].lower() == 'faculty_history':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 22\n",
    "        K = 12\n",
    "        dataset = 'FacultyHiringNetworks/History/History_FM_Full_'\n",
    "        dataset_print = 'Faculty: History'\n",
    "    elif dataset[:8].lower() == 'football':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 19\n",
    "        K = 9\n",
    "        dataset = 'Football_data_England_Premier_League/England_' + str(season) + '_' + str(season+1)\n",
    "        dataset_print = 'Football({})'.format(season)\n",
    "    elif dataset[:14].lower() == 'finer_football':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 4\n",
    "        K = 9\n",
    "        dataset = 'Football_data_England_Premier_League/finerEngland_' + str(season) + '_' + str(season+1)\n",
    "        dataset_print = 'Football finer({})'.format(season)\n",
    "    return dataset_print, dataset, K, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e170cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_ratio_coeff=1.0\n",
    "upset_margin_coeff=1.0\n",
    "upset_margin=0.01\n",
    "p=0.1\n",
    "AllTrain=True\n",
    "eta=0.1\n",
    "lr=0.01\n",
    "N=350\n",
    "ERO_style='uniform'\n",
    "dropout=0.5\n",
    "rank_baseline='syncRank'\n",
    "sigma=1.0\n",
    "pretrain_epochs=50\n",
    "dataset='finer_basketball'\n",
    "train_with='proximal_baseline'\n",
    "trainable_alpha=True\n",
    "pretrain_with='serial_similarity'\n",
    "method_of_interest='ib_proximal_baseline'\n",
    "aggregation='ib'\n",
    "F_style = 'path'\n",
    "sp_style = 'random'\n",
    "num_trials = 2\n",
    "seed = 31\n",
    "fill_val = 0.5\n",
    "ambient = 0\n",
    "Fiedler_layer_num = 5\n",
    "alpha = 1\n",
    "seeds = [10, 20, 30, 40, 50]\n",
    "in_dataset = dataset\n",
    "\n",
    "if dataset in ['basketball', 'finer_basketball']:\n",
    "    season_range = np.arange(1985, 2015)\n",
    "else:\n",
    "    season_range = np.arange(2009,2015)\n",
    "\n",
    "final_upset_all = np.zeros((len(season_range), 12, 10, NUM_UPSET_CHOICES))\n",
    "final_upset_all[:] = np.nan\n",
    "original_ind = GNN_names.index(method_of_interest)\n",
    "new_ind = original_ind % 6\n",
    "dataset_name_print = []\n",
    "for i, season in enumerate(season_range):\n",
    "    dataset_print, dataset, K, hidden = dataset_and_K(in_dataset, season)\n",
    "    if dataset[:3] != 'ERO':\n",
    "        num_trials = 10\n",
    "        AllTrain = True\n",
    "        train_ratio = 1\n",
    "        test_ratio = 1\n",
    "        seeds = [10]\n",
    "    # original GNN results\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=all_GNNs, K=K, train_with=train_with, \n",
    "                                   upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                    trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                   train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, rank_baseline=rank_baseline, \n",
    "                                   sigma=sigma, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with)\n",
    "    method_str, compare_names_all = generate_method_str_and_compare_names_all(all_GNNs)\n",
    "    dir_name = '../result_arrays/'+dataset\n",
    "    final_upset = np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy')[original_ind:original_ind+1]\n",
    "\n",
    "\n",
    "    # inductive GNN results\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=[aggregation], K=K, train_with=train_with, \n",
    "                                   upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                    trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                   train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, rank_baseline=rank_baseline, \n",
    "                                   sigma=sigma, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with)\n",
    "    method_str, _ = generate_method_str_and_compare_names_all([aggregation])\n",
    "    dir_name = '../result_arrays_inductive/'+dataset\n",
    "    inductive_final_upset = np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy')[new_ind:new_ind+1]\n",
    "    final_upset = np.concatenate((inductive_final_upset, final_upset), axis=0)\n",
    "    compare_names_all = ['inductive', 'original']\n",
    "\n",
    "\n",
    "    # try to include mvr results\n",
    "    dir_name = '../result_arrays/'+dataset\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=mvr, K=K, train_with=train_with,\n",
    "                                   upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                    trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                   train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, rank_baseline=rank_baseline, \n",
    "                                   sigma=sigma, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with)\n",
    "    method_str, _ = generate_method_str_and_compare_names_all(mvr)\n",
    "    if os.path.exists(os.path.join(dir_name,'kendalltau',method_str,save_name) + '.npy'):\n",
    "        final_upset = np.concatenate((np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy'), final_upset), axis=0)\n",
    "        compare_names_all = ['mvr'] + compare_names_all\n",
    "\n",
    "\n",
    "    # include baseline results\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=baselines, K=K, train_with=train_with, \n",
    "                                   upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                    trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                   train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, rank_baseline=rank_baseline, \n",
    "                                   sigma=sigma, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with)\n",
    "    method_str, compare_names_baselines = generate_method_str_and_compare_names_all(baselines)\n",
    "    if os.path.exists(os.path.join(dir_name,'kendalltau',method_str,save_name) + '.npy'):\n",
    "        final_upset = np.concatenate((np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy'), final_upset), axis=0)\n",
    "        compare_names_all = compare_names_baselines + compare_names_all\n",
    "    final_upset_all[i] = final_upset\n",
    "    dataset_name_print.append(dataset_print)\n",
    "for i, metric in enumerate(['upset simple', 'upset ratio', 'upset naive']):\n",
    "    title_name = metric\n",
    "    results_to_print = final_upset_all[:,:,:,i].swapaxes(0,2)\n",
    "    print_overall_performance_mean_std(title_name, results_to_print, \n",
    "                    compare_names_all, dataset_name_print, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef63a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_simple = final_upset_all[:,-1,:,0].mean(axis=0)\n",
    "upset_naive = final_upset_all[:,-1,:,2].mean(axis=0)\n",
    "upset_ratio = final_upset_all[:,-1,:,1].mean(axis=0)\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_simple.mean(), upset_simple.std())) #  new trained\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_naive.mean(), upset_naive.std())) #  new trained\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_ratio.mean(), upset_ratio.std())) #  new trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_simple = final_upset_all[:,-2,:,0].mean(axis=0)\n",
    "upset_naive = final_upset_all[:,-2,:,2].mean(axis=0)\n",
    "upset_ratio = final_upset_all[:,-2,:,1].mean(axis=0)\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_simple.mean(), upset_simple.std())) # directly apply\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_naive.mean(), upset_naive.std()))\n",
    "print('{:.4f}\\pm {:.4f}'.format(upset_ratio.mean(), upset_ratio.std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7d80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('dgl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fea18b2a1a69a86b3315cc7cd2a706ccbb2eae9ae7d74e28b20efaca82a4aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
