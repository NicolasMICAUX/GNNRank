{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce82d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "\n",
    "from metrics import print_and_analysis_performance_mean_std, print_ablation_performance_mean_std, print_overall_performance_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd8487b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "alpha = 1\n",
    "seeds = [10, 20, 30, 40, 50]\n",
    "selected_metrics = ['kendall tau', 'upset simple', 'upset ratio']\n",
    "METRICS_NUM = len(selected_metrics)\n",
    "baselines = ['SpringRank','syncRank','serialRank','btl', 'davidScore',\n",
    "        'eigenvectorCentrality', 'PageRank', 'rankCentrality', 'SVD_RS', 'SVD_NRS']\n",
    "GNN_selection_choices = ['lr', 'train with', 'pretrain with', 'upset margin coeff', \\\n",
    "                'imbalance coeff', 'unnormalized L', 'trainable alpha', 'baseline', \\\n",
    "                         'upset ratio coeff', 'Fiedler layer num', 'pretrain epochs']\n",
    "GNN_selection_choices_curr = ['lr', 'train with', 'pretrain with', 'upset margin coeff', 'trainable alpha', \\\n",
    "                 'baseline', 'upset ratio coeff', 'Fiedler layer num', 'pretrain epochs']\n",
    "GNN_CHOICES_NUM = len(GNN_selection_choices)\n",
    "GNN_CHOICES_NUM_CURR = len(GNN_selection_choices_curr)\n",
    "mvr = ['mvr']\n",
    "all_GNNs = ['DIGRAC', 'ib']\n",
    "desirable_list = [1, 2, 5]\n",
    "train_with_list = ['anchor_dist', 'anchor_innerproduct', 'emb_dist', 'emb_innerproduct','emb_baseline']\n",
    "imbalance_list = [0] # [0, 1]\n",
    "\n",
    "GNN_variant_names = ['clustering'] + train_with_list\n",
    "GNN_NUM = 12\n",
    "\n",
    "def generate_method_str_and_compare_names_all(all_methods=baselines, normalizations=['plain'], thresholds=['sort']):\n",
    "    method_str = ''\n",
    "    for method_name in all_methods:\n",
    "        method_str += method_name\n",
    "    if 'DIGRAC' in all_methods or 'ib' in all_methods:\n",
    "        method_str += 'normalizations_'\n",
    "        for normalization in normalizations:\n",
    "            method_str += normalization\n",
    "        method_str += 'thresholds_'\n",
    "        for threshold in thresholds:\n",
    "            method_str += threshold  \n",
    "    compare_names_all = []\n",
    "    for method_name in all_methods:\n",
    "        if method_name not in ['DIGRAC', 'ib']:\n",
    "            compare_names_all.append(method_name)\n",
    "        else:\n",
    "            for normalization in normalizations:\n",
    "                for threshold in thresholds:\n",
    "                    for GNN_type in GNN_variant_names:\n",
    "                        compare_names_all.append(method_name+'_'+normalization+'_'+threshold+'_'+GNN_type)\n",
    "    return method_str, compare_names_all\n",
    "\n",
    "methods_of_interest = ['ratio+margin','upset margin only', 'upset ratio only']\n",
    "        \n",
    "GNN_names = []\n",
    "for method_name in ['DIGRAC', 'ib']:\n",
    "    for GNN_type in GNN_variant_names:\n",
    "        GNN_names.append(method_name+'_plain_sort_'+GNN_type)\n",
    "\n",
    "non_proximal_ind = [1, 2, 7, 8] # removed 0 and 6 for \"clustering\" variant\n",
    "proximal_ind = [3, 4, 5, 9, 10, 11]\n",
    "NON_PROXIMAL_GNN_NUM = len(non_proximal_ind)\n",
    "PROXIMAL_GNN_NUM = len(proximal_ind)\n",
    "non_proximal_bool = np.zeros(GNN_NUM, dtype=bool)\n",
    "proximal_bool = np.zeros(GNN_NUM, dtype=bool)\n",
    "for i in non_proximal_ind:\n",
    "    non_proximal_bool[i] = True\n",
    "for i in proximal_ind:\n",
    "    proximal_bool[i] = True\n",
    "\n",
    "GNN_names_non_proximal = ['DIGRAC_plain_sort_anchor_dist', 'DIGRAC_plain_sort_anchor_innerproduct',\\\n",
    "                          'ib_plain_sort_anchor_dist', 'ib_plain_sort_anchor_innerproduct']\n",
    "GNN_names_proximal = ['DIGRAC_plain_sort_emb_dist', 'DIGRAC_plain_sort_emb_innerproduct', 'DIGRAC_plain_sort_emb_baseline', \\\n",
    "                      'ib_plain_sort_emb_dist', 'ib_plain_sort_emb_innerproduct', 'ib_plain_sort_emb_baseline']\n",
    "\n",
    "\n",
    "compare_names_all = methods_of_interest\n",
    "METHODS_NUM = len(compare_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e9905e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DIGRAC_plain_sort_clustering': 'DIGRAC clustering', 'DIGRAC_plain_sort_anchor_dist': 'DIGRAC dist', 'DIGRAC_plain_sort_anchor_innerproduct': 'DIGRAC innerproduct', 'ib_plain_sort_clustering': 'ib clustering', 'ib_plain_sort_anchor_dist': 'ib dist', 'ib_plain_sort_anchor_innerproduct': 'ib innerproduct', 'DIGRAC_plain_sort_emb_dist': 'DIGRAC proximal dist', 'DIGRAC_plain_sort_emb_innerproduct': 'DIGRAC proximal innerproduct', 'DIGRAC_plain_sort_emb_baseline': 'DIGRAC proximal baseline', 'ib_plain_sort_emb_dist': 'ib proximal dist', 'ib_plain_sort_emb_innerproduct': 'ib proximal innerproduct', 'ib_plain_sort_emb_baseline': 'ib proximal baseline', 'anchor_dist': 'dist', 'anchor_innerproduct': 'innerproduct', 'emb_dist': 'proximal dist', 'emb_innerproduct': 'proximal innerproduct', 'emb_baseline': 'proximal baseline', 'dist': 'dist', 'innerproduct': 'innerproduct', 'serial_similarity': 'SerialRank similarity'}\n"
     ]
    }
   ],
   "source": [
    "keys = ['DIGRAC_plain_sort_clustering', 'DIGRAC_plain_sort_anchor_dist', 'DIGRAC_plain_sort_anchor_innerproduct',\\\n",
    "                          'ib_plain_sort_clustering', 'ib_plain_sort_anchor_dist', 'ib_plain_sort_anchor_innerproduct', \\\n",
    "        'DIGRAC_plain_sort_emb_dist', 'DIGRAC_plain_sort_emb_innerproduct', 'DIGRAC_plain_sort_emb_baseline', \\\n",
    "                      'ib_plain_sort_emb_dist', 'ib_plain_sort_emb_innerproduct', 'ib_plain_sort_emb_baseline', \\\n",
    "       ]\n",
    "values = ['DIGRAC clustering', 'DIGRAC dist', 'DIGRAC innerproduct',\\\n",
    "                          'ib clustering', 'ib dist', 'ib innerproduct', \\\n",
    "        'DIGRAC proximal dist', 'DIGRAC proximal innerproduct', 'DIGRAC proximal baseline', \\\n",
    "                      'ib proximal dist', 'ib proximal innerproduct', 'ib proximal baseline']\n",
    "\n",
    "keys += train_with_list + ['dist', 'innerproduct', 'serial_similarity']\n",
    "values += ['dist', 'innerproduct', 'proximal dist', 'proximal innerproduct','proximal baseline'] + \\\n",
    "['dist', 'innerproduct', 'SerialRank similarity']\n",
    "name_mapping_dict = dict(zip(keys, values))\n",
    "print(name_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_dict = {}\n",
    "eta_list_dict = {}\n",
    "ERO_style_list_dict = {}\n",
    "K_list_dict = {}\n",
    "size_ratio_list_dict = {}\n",
    "season_list_dict = {}\n",
    "season_list_dict['basketball'] = np.arange(1985, 2015)\n",
    "season_list_dict['finer_basketball'] = np.arange(1985, 2015)\n",
    "season_list_dict['football'] = np.arange(2009, 2015)\n",
    "season_list_dict['finer_football'] = np.arange(2009, 2015)\n",
    "for dataset in ['finance','animal', 'faculty_business', 'faculty_cs', 'faculty_history', 'HeadToHead', 'DSBM', 'ERO']:\n",
    "    season_list_dict[dataset] = [2009]\n",
    "for dataset in ['basketball', 'finer_basketball', 'football', 'finer_football', 'finance','animal', 'faculty_business', 'faculty_cs', 'faculty_history', 'HeadToHead']:\n",
    "    p_list_dict[dataset] = [0.05]\n",
    "    eta_list_dict[dataset] = [0]\n",
    "    K_list_dict[dataset] = [5]\n",
    "    size_ratio_list_dict[dataset] = [1.5]\n",
    "    ERO_style_list_dict[dataset] = ['uniform']\n",
    "p_list_dict['DSBM'] = [0.05]\n",
    "eta_list_dict['DSBM'] = [0, 0.1]\n",
    "K_list_dict['DSBM'] = [5, 10, 20]\n",
    "size_ratio_list_dict['DSBM'] = [1, 1.5, 2]\n",
    "ERO_style_list_dict['DSBM'] = ['uniform']\n",
    "\n",
    "p_list_dict['ERO'] = [0.05, 1]\n",
    "eta_list_dict['ERO'] = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "K_list_dict['ERO'] = [5]\n",
    "size_ratio_list_dict['ERO'] = [1]\n",
    "ERO_style_list_dict['ERO'] = ['uniform', 'gamma']\n",
    "pretrain_with_list_dict = {}\n",
    "for train_with in train_with_list:\n",
    "    if train_with[:3] == 'emb':\n",
    "        pretrain_with_list_dict[train_with] = ['dist', 'innerproduct', 'serial_similarity']\n",
    "    else:\n",
    "        pretrain_with_list_dict[train_with] = ['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a5458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_save_name(dataset='HeadToHead', all_methods=all_GNNs, K=5, train_with='anchor_dist', imbalance_coeff=1, upset_ratio_coeff=1.0, upset_margin_coeff=0, upset_margin=0.01,\n",
    "                           trainable_alpha=False, lr=0.01, hidden=32, num_trials=10, train_ratio=1, test_ratio=1,  AllTrain=True, cluster_rank_baseline='SpringRank', sigma=1.0, \n",
    "                           Fiedler_layer_num=5, pretrain_epochs=50, pretrain_with='dist'):\n",
    "    default_name_base = ''\n",
    "    if 'DIGRAC' in all_methods or 'ib' in all_methods:\n",
    "        default_name_base += 'K' + str(K) + 'dropout' + str(int(100*dropout))\n",
    "        default_name_base += 'imb_coe' + str(int(100*imbalance_coeff)) + 'ratio_coe' + str(int(100*upset_ratio_coeff)) + 'margin_coe' + str(int(100*upset_margin_coeff)) \n",
    "        if upset_margin_coeff > 0:\n",
    "            default_name_base += 'margin' + str(int(100*upset_margin)) \n",
    "        default_name_base += 'with' + str(train_with)  + 'Fiedler' + str(Fiedler_layer_num) + 'sigma' + str(int(100*sigma))\n",
    "        default_name_base += 'alpha' + str(int(100*alpha)) + 'train_alpha' + str(trainable_alpha) + 'hid' + str(hidden) + 'lr' + str(int(1000*lr))\n",
    "        default_name_base += 'use' + str(cluster_rank_baseline)\n",
    "        if pretrain_epochs > 0 and train_with[:3] == 'emb':\n",
    "            default_name_base +=  'pre' + str(pretrain_with) + str(int(pretrain_epochs))\n",
    "    save_name_base = default_name_base\n",
    "\n",
    "    default_name_base +=  'trials' + str(num_trials) + 'train_r' + str(int(100*train_ratio)) + 'test_r' + str(int(100*test_ratio)) + 'All' + str(AllTrain)\n",
    "    if dataset[:4] == 'DSBM' or dataset[:3] == 'ERO':\n",
    "        default_name_base += 'seeds' + '_'.join([str(value) for value in np.array(seeds).flatten()])\n",
    "    return default_name_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_and_K(dataset, season=2009, K=5, p=0.05, size_ratio=1.5, ERO_style='uniform', eta=0.1, N=350):\n",
    "    F_style = 'path'\n",
    "    sp_style = 'random'\n",
    "    ambient = 0\n",
    "    if dataset[-1]!='/':\n",
    "        dataset += '/'\n",
    "\n",
    "    if dataset[:4] == 'DSBM':\n",
    "        hidden = 8\n",
    "        default_name_base = F_style+ '_' + sp_style\n",
    "        default_name_base += 'p' + str(int(100*p)) + 'K' + str(K) + 'N' + str(N) + 'size_r' + str(int(100*size_ratio))\n",
    "        default_name_base += 'eta' + str(int(100*eta)) + 'ambient' + str(ambient)\n",
    "        dataset = 'DSBM/' + default_name_base\n",
    "        dataset_print = 'DSBM(p={}, K={}, size ratio={},$\\eta$={})'.format(p, K, size_ratio, eta)\n",
    "    elif dataset[:3] == 'ERO':\n",
    "        hidden = 8\n",
    "        K = 5\n",
    "        F = 3\n",
    "        default_name_base = 'p' + str(int(100*p)) + 'K' + str(K) + 'N' + str(N)\n",
    "        default_name_base += 'eta' + str(int(100*eta)) + 'style' + str(ERO_style)\n",
    "        dataset = 'ERO/' + default_name_base\n",
    "        dataset_print = 'ERO(p={}, style={},$\\eta$={})'.format(p, ERO_style, eta)\n",
    "    elif dataset[:10].lower() == 'basketball':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 70\n",
    "        K = 20\n",
    "        dataset = 'Basketball_temporal/' + str(season)\n",
    "        dataset_print = 'Basketball({})'.format(season)\n",
    "    elif dataset[:16].lower() == 'finer_basketball':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 2\n",
    "        K = 20\n",
    "        dataset = 'Basketball_temporal/finer' + str(season)\n",
    "        dataset_print = 'Basketball finer({})'.format(season)\n",
    "    elif dataset[:6].lower() == 'animal':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 3\n",
    "        K = 3\n",
    "        dataset = 'Dryad_animal_society/'\n",
    "        dataset_print = 'Animal'\n",
    "    elif dataset[:7].lower() == 'finance':\n",
    "        hidden = 32\n",
    "        hidden_compare = 32\n",
    "        F = 5 # threshold: > 0.7, others have threshold > 0.9\n",
    "        K = 20\n",
    "        dataset_print = 'Finance'\n",
    "    elif dataset[:10].lower() == 'headtohead':\n",
    "        hidden = 16\n",
    "        hidden_compare = 16\n",
    "        F = 39\n",
    "        K = 48\n",
    "        dataset = 'Halo2BetaData/HeadToHead'\n",
    "        dataset_print = 'HeadToHead'\n",
    "    elif dataset[:16].lower() == 'faculty_business':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 6\n",
    "        K = 5\n",
    "        dataset = 'FacultyHiringNetworks/Business/Business_FM_Full_'\n",
    "        dataset_print = 'Faculty: Business'\n",
    "    elif dataset[:10].lower() == 'faculty_cs':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 8\n",
    "        K = 9\n",
    "        dataset = 'FacultyHiringNetworks/ComputerScience/ComputerScience_FM_Full_'\n",
    "        dataset_print = 'Faculty: CS'\n",
    "    elif dataset[:15].lower() == 'faculty_history':\n",
    "        hidden = 8\n",
    "        hidden_compare = 8\n",
    "        F = 22\n",
    "        K = 12\n",
    "        dataset = 'FacultyHiringNetworks/History/History_FM_Full_'\n",
    "        dataset_print = 'Faculty: History'\n",
    "    elif dataset[:8].lower() == 'football':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 19\n",
    "        K = 9\n",
    "        dataset = 'Football_data_England_Premier_League/England_' + str(season) + '_' + str(season+1)\n",
    "        dataset_print = 'Football({})'.format(season)\n",
    "    elif dataset[:14].lower() == 'finer_football':\n",
    "        hidden = 4\n",
    "        hidden_compare = 4\n",
    "        F = 4\n",
    "        K = 9\n",
    "        dataset = 'Football_data_England_Premier_League/finerEngland_' + str(season) + '_' + str(season+1)\n",
    "        dataset_print = 'Football finer({})'.format(season)\n",
    "    return '{\\it '+dataset_print+'}', dataset, K, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6707b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.01, 0.05, 0.005]\n",
    "upset_margin_coeff_list = [0, 1]\n",
    "imbalance_coeff_list = [0] # [0, 1]\n",
    "unnormalized_L_list = [True] # [True, False]\n",
    "trainable_alpha_list = [False, True]\n",
    "cluster_rank_baseline_list = ['serialRank', 'SpringRank','syncRank','btl', \n",
    "        'eigenvectorCentrality', 'PageRank', 'SVD_NRS']\n",
    "upset_ratio_coeff_list = [0, 1]\n",
    "Fiedler_layer_num_list = [5]\n",
    "pretrain_epochs_list = [50]\n",
    "non_proximal_ind_correspondence_dict = {}\n",
    "proximal_ind_correspondence_dict = {}\n",
    "i = 0\n",
    "for lr_ind, lr in enumerate(lr_list):\n",
    "    for train_ind, train_with in enumerate(train_with_list):\n",
    "        for pretrain_ind, pretrain_with in enumerate(pretrain_with_list_dict[train_with]):\n",
    "            for margin_coeff_ind, upset_margin_coeff in enumerate(upset_margin_coeff_list):\n",
    "                for imb_coeff_ind, imbalance_coeff in enumerate(imbalance_coeff_list):\n",
    "                    for unnormalized_L_ind, unnormalized_L in enumerate(unnormalized_L_list):\n",
    "                        for trainable_alpha_ind, trainable_alpha in enumerate(trainable_alpha_list):\n",
    "                            for cluster_base_ind, cluster_rank_baseline in enumerate(cluster_rank_baseline_list):\n",
    "                                for ratio_coeff_ind, upset_ratio_coeff in enumerate(upset_ratio_coeff_list):\n",
    "                                    for Fiedler_layer_num_ind, Fiedler_layer_num in enumerate(Fiedler_layer_num_list):\n",
    "                                        for pretrain_epochs_ind, pretrain_epochs in enumerate(pretrain_epochs_list):\n",
    "                                            for method_ind in range(NON_PROXIMAL_GNN_NUM):\n",
    "                                                non_proximal_ind_correspondence_dict[i] = [lr_ind, train_ind, pretrain_ind, \\\n",
    "                                                                              margin_coeff_ind, imb_coeff_ind, \\\n",
    "                                                                             unnormalized_L_ind, trainable_alpha_ind, \\\n",
    "                                                                             cluster_base_ind, ratio_coeff_ind, \\\n",
    "                                                                            Fiedler_layer_num_ind, pretrain_epochs_ind, method_ind]\n",
    "                                                i += 1\n",
    "i = 0\n",
    "for lr_ind, lr in enumerate(lr_list):\n",
    "    for train_ind, train_with in enumerate(train_with_list):\n",
    "        for pretrain_ind, pretrain_with in enumerate(pretrain_with_list_dict[train_with]):\n",
    "            for margin_coeff_ind, upset_margin_coeff in enumerate(upset_margin_coeff_list):\n",
    "                for imb_coeff_ind, imbalance_coeff in enumerate(imbalance_coeff_list):\n",
    "                    for unnormalized_L_ind, unnormalized_L in enumerate(unnormalized_L_list):\n",
    "                        for trainable_alpha_ind, trainable_alpha in enumerate(trainable_alpha_list):\n",
    "                            for cluster_base_ind, cluster_rank_baseline in enumerate(cluster_rank_baseline_list):\n",
    "                                for ratio_coeff_ind, upset_ratio_coeff in enumerate(upset_ratio_coeff_list):\n",
    "                                    for Fiedler_layer_num_ind, Fiedler_layer_num in enumerate(Fiedler_layer_num_list):\n",
    "                                        for pretrain_epochs_ind, pretrain_epochs in enumerate(pretrain_epochs_list):\n",
    "                                            for method_ind in range(PROXIMAL_GNN_NUM):\n",
    "                                                proximal_ind_correspondence_dict[i] = [lr_ind, train_ind, pretrain_ind, \\\n",
    "                                                                              margin_coeff_ind, imb_coeff_ind, \\\n",
    "                                                                             unnormalized_L_ind, trainable_alpha_ind, \\\n",
    "                                                                             cluster_base_ind, ratio_coeff_ind, \\\n",
    "                                                                            Fiedler_layer_num_ind, pretrain_epochs_ind, method_ind]\n",
    "                                                i += 1\n",
    "non_proximal_cases_num = len(non_proximal_ind_correspondence_dict.keys())\n",
    "proximal_cases_num = len(proximal_ind_correspondence_dict.keys())\n",
    "print(non_proximal_cases_num, proximal_cases_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56b4f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_load_results(dataset=dataset, all_methods=all_GNNs, K=5, train_with='anchor_dist', imbalance_coeff=0, \n",
    "                                   upset_ratio_coeff=1, upset_margin_coeff=0,  upset_margin=0.01,\n",
    "                                    trainable_alpha=False, lr=0.01, hidden=32, num_trials=10, \n",
    "                                   train_ratio=0.8, test_ratio=0.1,  AllTrain=True, cluster_rank_baseline='SpringRank', \n",
    "                                   sigma=1, Fiedler_layer_num=5, pretrain_epochs=50, pretrain_with='dist', unnormalized_L=False):\n",
    "    normalizations = ['plain']\n",
    "    thresholds = ['sort']\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=all_GNNs, K=K, train_with=train_with, imbalance_coeff=imbalance_coeff, \n",
    "                                   upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                    trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                   train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, cluster_rank_baseline=cluster_rank_baseline, \n",
    "                                   sigma=sigma, Fiedler_layer_num=Fiedler_layer_num, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with)\n",
    "    method_str, _ = generate_method_str_and_compare_names_all(all_GNNs, normalizations, thresholds)\n",
    "    assert unnormalized_L == True\n",
    "    dir_name = '../result_arrays0107/'+dataset\n",
    "    '''\n",
    "    if lr == 0.01:\n",
    "        dir_name = '../result_arrays0107/'+dataset\n",
    "        assert unnormalized_L == True # , 'lr={}, trainable_alpha={}, unnormalized_L={}'.format(lr, trainable_alpha, unnormalized_L)\n",
    "    else:\n",
    "        dir_name = '../result_arrays/'+dataset\n",
    "        assert unnormalized_L == False # , 'lr={}, trainable_alpha={}, unnormalized_L={}'.format(lr, trainable_alpha, unnormalized_L)\n",
    "    '''\n",
    "    kendalltau_res = None\n",
    "    # try:\n",
    "    if dataset[:3] == 'ERO' or dataset[:4] == 'DSBM':\n",
    "        kendalltau_res = np.load(os.path.join(dir_name,'kendalltau',method_str,save_name) + '.npy')[:, :, 2, 0]\n",
    "    final_upset = np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy')\n",
    "    # except FileNotFoundError:\n",
    "        # print(os.path.join(dir_name,'kendalltau',method_str,save_name) + '.npy')\n",
    "    return kendalltau_res, final_upset[:, :, 0], final_upset[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b38600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_selection_with_fix_dim(dataset, K, train_ratio, test_ratio, AllTrain, hidden, num_trials, constraint='original'):\n",
    "    # print(dataset, K, train_ratio, test_ratio, AllTrain, hidden, num_trials)\n",
    "    upset_margin = 0.01\n",
    "    pretrain_epochs = 50\n",
    "    sigma = 1\n",
    "    full_results_non_proximal = 1000*np.ones((METRICS_NUM, NON_PROXIMAL_GNN_NUM * non_proximal_cases_num))\n",
    "    full_results_non_proximal[0] = 0\n",
    "    final_ind_non_proximal = 0\n",
    "    has_result = False\n",
    "    for lr_ind, lr in enumerate(lr_list):\n",
    "        for train_ind, train_with in enumerate(train_with_list):\n",
    "            for pretrain_ind, pretrain_with in enumerate(pretrain_with_list_dict[train_with]):\n",
    "                for margin_coeff_ind, upset_margin_coeff in enumerate(upset_margin_coeff_list):\n",
    "                    for imb_coeff_ind, imbalance_coeff in enumerate(imbalance_coeff_list):\n",
    "                        for unnormalized_L_ind, unnormalized_L in enumerate(unnormalized_L_list):\n",
    "                            for trainable_alpha_ind, trainable_alpha in enumerate(trainable_alpha_list):\n",
    "                                for cluster_base_ind, cluster_rank_baseline in enumerate(cluster_rank_baseline_list):\n",
    "                                    for ratio_coeff_ind, upset_ratio_coeff in enumerate(upset_ratio_coeff_list):\n",
    "                                        for Fiedler_layer_num_ind, Fiedler_layer_num in enumerate(Fiedler_layer_num_list):\n",
    "                                            for pretrain_epochs_ind, pretrain_epochs in enumerate(pretrain_epochs_list):\n",
    "                                                try:\n",
    "                                                    if constraint == 'upset margin only':\n",
    "                                                        assert upset_margin_coeff == 1 and upset_ratio_coeff == 0 and Fiedler_layer_num == 5 and pretrain_epochs == 50\n",
    "                                                    elif constraint == 'upset ratio only':\n",
    "                                                        assert upset_margin_coeff == 0 and upset_ratio_coeff == 1 and Fiedler_layer_num == 5 and pretrain_epochs == 50\n",
    "                                                    elif constraint == 'ratio+margin':\n",
    "                                                        assert upset_margin_coeff == 1 and upset_ratio_coeff == 1\n",
    "                                                    kendalltau, upset_simple, upset_ratio = GNN_load_results(dataset=dataset, all_methods=all_GNNs, K=K, train_with=train_with, imbalance_coeff=imbalance_coeff, \n",
    "                                                           upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                                            trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                                           train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, cluster_rank_baseline=cluster_rank_baseline, \n",
    "                                                           sigma=sigma, Fiedler_layer_num=Fiedler_layer_num, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with, unnormalized_L=unnormalized_L)\n",
    "                                                    if kendalltau is not None:\n",
    "                                                        mean_kendalltau = np.nanmean(kendalltau[non_proximal_bool], axis=1)\n",
    "                                                        full_results_proximal[0, final_ind_non_proximal: final_ind_non_proximal + NON_PROXIMAL_GNN_NUM] = mean_kendalltau\n",
    "\n",
    "                                                    mean_upset_simple = upset_simple[non_proximal_bool].mean(axis=1)\n",
    "                                                    mean_upset_ratio = upset_ratio[non_proximal_bool].mean(axis=1)      \n",
    "                                                    full_results_non_proximal[1, final_ind_non_proximal: final_ind_non_proximal + NON_PROXIMAL_GNN_NUM] = mean_upset_simple\n",
    "                                                    full_results_non_proximal[2, final_ind_non_proximal: final_ind_non_proximal + NON_PROXIMAL_GNN_NUM] = mean_upset_ratio\n",
    "                                                    has_result = True\n",
    "                                                except FileNotFoundError:\n",
    "                                                    # print(dataset, lr, upset_ratio_coeff, upset_margin_coeff, hidden, num_trials, \\\n",
    "                                                          # trainable_alpha, train_ratio, test_ratio, AllTrain, cluster_rank_baseline, \\\n",
    "                                                         # unnormalized_L, train_with, pretrain_with)\n",
    "                                                    pass\n",
    "                                                except AssertionError:\n",
    "                                                    #print(lr, upset_ratio_coeff, upset_margin_coeff, hidden, num_trials, \\\n",
    "                                                          # trainable_alpha, train_ratio, test_ratio, AllTrain, cluster_rank_baseline, \\\n",
    "                                                         # unnormalized_L, train_with, pretrain_with)\n",
    "                                                    pass\n",
    "                                                final_ind_non_proximal += NON_PROXIMAL_GNN_NUM\n",
    "    if has_result:\n",
    "        best_ind = np.zeros((METRICS_NUM, 1))\n",
    "        best_vals = np.array([[0], [1000], [1000]], dtype=np.float64)\n",
    "        if dataset[:4] == 'DSBM' or dataset[:3] == 'ERO':\n",
    "            full_results_proximal[0] = np.nan_to_num(full_results_proximal[0], nan=0)\n",
    "            best_ind[0, 0] = full_results_proximal[0].argmax()\n",
    "            best_vals[0, 0] = np.nanmax(full_results_proximal[0])\n",
    "\n",
    "        full_results_non_proximal[1] = np.nan_to_num(full_results_non_proximal[1], nan=1000)\n",
    "        full_results_non_proximal[2] = np.nan_to_num(full_results_non_proximal[2], nan=1000)\n",
    "        best_vals[1, 0] = np.nanmin(full_results_non_proximal[1])\n",
    "        best_vals[2, 0] = np.nanmin(full_results_non_proximal[2])\n",
    "        best_ind[1, 0] = full_results_non_proximal[1].argmin()\n",
    "        best_ind[2, 0] = full_results_non_proximal[2].argmin()\n",
    "        selected_indices = np.zeros((METRICS_NUM, 1, GNN_CHOICES_NUM+1))\n",
    "        kendalltau_res = np.zeros((METRICS_NUM, 1, 10))\n",
    "        kendalltau_res[:] = np.nan\n",
    "        final_upset = np.zeros((METRICS_NUM, 1, 10, 2)) # the first \"1\" means proximal\n",
    "        final_upset[:] = np.nan\n",
    "        # print('Best values are {}.'.format(best_vals))\n",
    "        for i in range(METRICS_NUM):\n",
    "            if i == 0 and dataset[:4] != 'DSBM' and dataset[:3] != 'ERO':\n",
    "                continue\n",
    "            j = 0\n",
    "            selected_indices[i, j] = non_proximal_ind_correspondence_dict[best_ind[i, j]]\n",
    "                \n",
    "            lr = lr_list[int(selected_indices[i, j, 0])]\n",
    "            train_with = train_with_list[int(selected_indices[i, j, 1])]\n",
    "            pretrain_with = pretrain_with_list_dict[train_with][int(selected_indices[i, j, 2])]\n",
    "            upset_margin_coeff = upset_margin_coeff_list[int(selected_indices[i, j, 3])]\n",
    "            imbalance_coeff = imbalance_coeff_list[int(selected_indices[i, j, 4])]\n",
    "            unnormalized_L = unnormalized_L_list[int(selected_indices[i, j, 5])]\n",
    "            trainable_alpha = trainable_alpha_list[int(selected_indices[i, j, 6])]\n",
    "            cluster_rank_baseline = cluster_rank_baseline_list[int(selected_indices[i, j, 7])]\n",
    "            upset_ratio_coeff = upset_ratio_coeff_list[int(selected_indices[i, j, 8])]\n",
    "            Fiedler_layer_num = Fiedler_layer_num_list[int(selected_indices[i, j, 9])]\n",
    "            pretrain_epochs = pretrain_epochs_list[int(selected_indices[i, j, 10])]\n",
    "\n",
    "            sel_ind = int(selected_indices[i, j, -1])\n",
    "            GNN_selected = GNN_names_non_proximal[sel_ind]\n",
    "            selected_vals = [lr, train_with, pretrain_with, upset_margin_coeff, \\\n",
    "                              imbalance_coeff, unnormalized_L, trainable_alpha, \\\n",
    "                             cluster_rank_baseline, upset_ratio_coeff, Fiedler_layer_num, pretrain_epochs]\n",
    "            \n",
    "            kendalltau, upset_simple, upset_ratio = GNN_load_results(dataset=dataset, all_methods=all_GNNs, K=K, train_with=train_with, imbalance_coeff=imbalance_coeff, \n",
    "                                       upset_ratio_coeff=upset_ratio_coeff, upset_margin_coeff=upset_margin_coeff, upset_margin=upset_margin,\n",
    "                                        trainable_alpha=trainable_alpha, lr=lr, hidden=hidden, num_trials=num_trials, \n",
    "                                       train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain, cluster_rank_baseline=cluster_rank_baseline, \n",
    "                                       sigma=sigma, Fiedler_layer_num=Fiedler_layer_num, pretrain_epochs=pretrain_epochs, pretrain_with=pretrain_with, unnormalized_L=unnormalized_L)\n",
    "            if kendalltau is not None:\n",
    "                kendalltau_res[i, j] = (kendalltau[non_proximal_bool])[sel_ind]\n",
    "            upset_simple_res = (upset_simple[non_proximal_bool])[sel_ind]\n",
    "            upset_ratio_res = (upset_ratio[non_proximal_bool])[sel_ind]\n",
    "            final_upset[i, j] = np.array([upset_simple_res, upset_ratio_res]).swapaxes(0,1)\n",
    "        return kendalltau_res, final_upset, selected_indices\n",
    "    else:\n",
    "        raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37391c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_results(dataset_list=['animal', 'faculty_business', 'faculty_cs', 'faculty_history', 'football', 'finer_football']):\n",
    "    dataset_name_full = []\n",
    "    kendalltau_res_all_full = []\n",
    "    final_upset_all_full = []\n",
    "    selected_indices_full = []\n",
    "    for dataset in dataset_list:\n",
    "        for p in p_list_dict[dataset]:\n",
    "                for K in K_list_dict[dataset]:\n",
    "                    for eta in eta_list_dict[dataset]:\n",
    "                        for ERO_style in ERO_style_list_dict[dataset]:\n",
    "                            for season in season_list_dict[dataset]:\n",
    "                                for size_ratio in size_ratio_list_dict[dataset]:\n",
    "                                    try:\n",
    "                                        dataset_long, kendalltau_res_all, final_upset_all, selected_indices = extract_results(dataset=dataset, \n",
    "                                                        season=season, p=p, K=K, eta=eta, size_ratio=size_ratio, \n",
    "                                                        ERO_style=ERO_style)\n",
    "                                        dataset_name_full.append(dataset_long)\n",
    "                                        kendalltau_res_all_full.append(kendalltau_res_all)\n",
    "                                        final_upset_all_full.append(final_upset_all)\n",
    "                                        selected_indices_full.append(selected_indices)\n",
    "                            \n",
    "                                    except FileNotFoundError:\n",
    "                                        print('No result yet for {}, season {}, p={}, K={}, size ratio = {}, eta={}, ERO style = {}.'.format(dataset,\n",
    "                                            season, p, K, size_ratio, eta, ERO_style))\n",
    "    \n",
    "\n",
    "    full_results = np.concatenate((np.expand_dims(np.array(kendalltau_res_all_full), axis=-1), np.array(final_upset_all_full)), axis=-1)\n",
    "    for i in range(METRICS_NUM):\n",
    "        for j in range(1, METRICS_NUM):\n",
    "            results_to_print = full_results[:,j,:,:,i].swapaxes(0,2)\n",
    "            if not np.isnan(results_to_print).all():\n",
    "                dataset_name_print = dataset_name_full\n",
    "                compare_names_print = compare_names_all\n",
    "                title_name = selected_metrics[i] + ' with best ' + selected_metrics[j]\n",
    "                print_overall_performance_mean_std(title_name, results_to_print, \n",
    "                                compare_names_print, dataset_name_print, True)\n",
    "    return dataset_name_full, final_upset_all_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(dataset, season=2009, K=5, upset_ratio_coeff=1.0, upset_margin=0.01, p=0.1, \n",
    "                       AllTrain=True, size_ratio=1.5, eta=0.1, lr=0.05, hidden=32, normalizations=['plain'], thresholds=['sort'],\n",
    "                        N=350, ERO_style='uniform', train_ratio = 0.8, test_ratio = 0.1, dropout=0.5, sigma=1.0, \n",
    "                           methods_of_interest=methods_of_interest, print_latex=True):\n",
    "    F_style = 'path'\n",
    "    sp_style = 'random'\n",
    "    num_trials = 2\n",
    "    seed = 31\n",
    "    fill_val = 0.5\n",
    "    ambient = 0\n",
    "    alpha = 1\n",
    "    seeds = [10, 20, 30, 40, 50]\n",
    "    normalizations = ['plain']\n",
    "    thresholds = ['sort']\n",
    "    \n",
    "    dataset_print, dataset, K, hidden = dataset_and_K(dataset, season, K, p, size_ratio, ERO_style, eta)\n",
    "\n",
    "    if dataset[:4] != 'DSBM' and dataset[:3] != 'ERO':\n",
    "        num_trials = 10\n",
    "        AllTrain = True\n",
    "        train_ratio = 1\n",
    "        test_ratio = 1\n",
    "        seeds = [10]\n",
    "    \n",
    "    kendalltau_res_full_list = []\n",
    "    final_upset_full_list = []\n",
    "    selected_indices_list = []\n",
    "    for constraint in methods_of_interest:\n",
    "        kendalltau_res_full, final_upset_full, selected_indices = GNN_selection_with_fix_dim(dataset, K, train_ratio, test_ratio, AllTrain, hidden, num_trials, constraint=constraint)\n",
    "        kendalltau_res_full_list.append(kendalltau_res_full)\n",
    "        final_upset_full_list.append(final_upset_full)\n",
    "        selected_indices_list.append(selected_indices)\n",
    "    dir_name = '../result_arrays/'+dataset\n",
    "    kendalltau_res_all = np.zeros((METRICS_NUM, METHODS_NUM, num_trials*len(seeds)))\n",
    "    kendalltau_res_all[:] = np.nan\n",
    "    final_upset_all = np.zeros((METRICS_NUM, METHODS_NUM, num_trials*len(seeds), 2))\n",
    "    final_upset_all[:] = np.nan\n",
    "    for i in range(METRICS_NUM):\n",
    "        compare_names_all = methods_of_interest\n",
    "        if i == 0 and dataset[:3] != 'ERO' and dataset[:4] != 'DSBM':\n",
    "            continue\n",
    "        # print('For the best {} model:'.format(selected_metrics[i]))\n",
    "        kendalltau_res = kendalltau_res_full_list[0][i]\n",
    "        final_upset = final_upset_full_list[0][i]\n",
    "        # print(i, final_upset.shape)\n",
    "        for j in np.arange(1, len(methods_of_interest)):\n",
    "            kendalltau_res = np.concatenate((kendalltau_res, kendalltau_res_full_list[j][i]), axis=0)\n",
    "            final_upset = np.concatenate((final_upset, final_upset_full_list[j][i]), axis=0)\n",
    "            # print(i, j, final_upset.shape)\n",
    "        kendalltau_res_all[i] = kendalltau_res\n",
    "        final_upset_all[i] = final_upset\n",
    "\n",
    "        \n",
    "    return dataset_print, kendalltau_res_all, final_upset_all, np.array(selected_indices_list).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_full, final_upset_all_full = analysis_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a768367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_full[-12:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_upset_all_full = np.array(final_upset_all_full)\n",
    "final_upset_all_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_overall_performance_mean_std('football', final_upset_all_full[-12:-6,1,:,:,0].mean(axis=0).swapaxes(0,1)[:,:, None], \n",
    "                                methods_of_interest, ['upset simple'], True)\n",
    "print_overall_performance_mean_std('football', final_upset_all_full[-12:-6,2,:,:,1].mean(axis=0).swapaxes(0,1)[:,:, None], \n",
    "                                methods_of_interest, ['upset ratio'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_overall_performance_mean_std('finer football', final_upset_all_full[-6:,1,:,:,0].mean(axis=0).swapaxes(0,1)[:,:, None], \n",
    "                                methods_of_interest, ['upset simple'], True)\n",
    "print_overall_performance_mean_std('finer football', final_upset_all_full[-6:,2,:,:,1].mean(axis=0).swapaxes(0,1)[:,:, None], \n",
    "                                methods_of_interest, ['upset ratio'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
