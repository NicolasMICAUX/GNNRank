{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_score(row, crit):\n",
    "    for item in row[\"criteria_scores\"]:\n",
    "        if item[\"criteria\"] == crit:\n",
    "            return item[\"score\"]\n",
    "\n",
    "def api_get_tournesol_scores():\n",
    "    \"\"\"Get a dataframe with all videos from tournesol..\"\"\"\n",
    "    true_scores_path = \"GNNRank/data/tournesol/true_scores.feather\"\n",
    "    if os.path.exists(true_scores_path):\n",
    "        return pd.read_feather(true_scores_path)\n",
    "    else:\n",
    "        response = requests.get(\n",
    "            f\"https://api.tournesol.app/video/?limit=9999&unsafe=true\"\n",
    "        ).json()\n",
    "        df = pd.DataFrame.from_dict(response[\"results\"])\n",
    "\n",
    "        for crit in CRITERIA:\n",
    "            df[crit] = df.apply(lambda x: get_score(x, crit), axis=1)\n",
    "\n",
    "        df.drop(columns=[\"criteria_scores\"], inplace=True)\n",
    "\n",
    "        # keep only columns [uid, publication_date, views, language,duration,largely_recommended,reliability,importance,engaging,pedagogy,layman_friendly,entertaining_relaxing,better_habits,diversity_inclusion,backfire_risk]\n",
    "        # i.e., drop ['name', 'description', 'uploader', 'video_id', rating_n_ratings,rating_n_contributors]\n",
    "\n",
    "        df.to_feather(true_scores_path)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = api_get_tournesol_scores()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandarallel'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01myoutube_dl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m YoutubeDL\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandarallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pandarallel\n\u001B[1;32m      5\u001B[0m metadata_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGNNRank/data/tournesol/true_scores_metadata.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(metadata_path):\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandarallel'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from youtube_dl import YoutubeDL\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "metadata_path = \"GNNRank/data/tournesol/true_scores_metadata.feather\"\n",
    "if os.path.isfile(metadata_path):\n",
    "    df = pd.read_feather(metadata_path)\n",
    "else:\n",
    "    # pas la bonne librairie (trouver une librairie de multi-threading !) pcq ma tâche est IO-bound.\n",
    "    pandarallel.initialize(nb_workers=20, progress_bar=True)\n",
    "\n",
    "    def convert_yt_id_to_url(yt_id):\n",
    "        \"\"\"convert 'yt:WPPPFqsECz0' to 'https://www.youtube.com/watch?v=WPPPFqsECz0'\"\"\"\n",
    "        if yt_id.startswith(\"yt:\"):\n",
    "            return f\"https://www.youtube.com/watch?v={yt_id[3:]}\"\n",
    "        else:\n",
    "            raise ValueError(f\"{yt_id} is not a valid youtube id\")\n",
    "\n",
    "    def extract_info(uid, ydl):\n",
    "        try:\n",
    "            info_dict = ydl.extract_info(convert_yt_id_to_url(uid), download=False)\n",
    "        except:\n",
    "            print(f\"uid={uid}\")\n",
    "            return '', [], np.nan\n",
    "        return info_dict['categories'][0], info_dict['tags'], info_dict['like_count']\n",
    "\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'ignoreerrors': False,  # ABSURDE : POUR QUE LES ERREURS N'INTERROMPT PAS LE PROCESSUS, IL FAUT DIRE IGNORE_ERRORS = FALSE !?!?\n",
    "    }\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        idx = df['category'].isna() & df['tags'].isna() if 'category' in df.columns else ~df['uid'].isna()\n",
    "        results = df[idx].parallel_apply(lambda x: extract_info(x['uid'], ydl), axis=1)\n",
    "        df.loc[idx, ['category']] = [r[0] for r in results]\n",
    "        df.loc[idx, ['tags']] = [r[1] for r in results]\n",
    "        df.loc[idx, ['like_count']] = [r[2] for r in results]\n",
    "    df.to_feather(metadata_path)\n",
    "\n",
    "# todo : nb d'abonnés de la chaîne, récupérer transcription pour analyse de complexité...\n",
    "# todo : scrap les commentaires, nb de commentaires."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert date to nb of monthes since 1970, add noise to the date (std = 1 month)\n",
    "data['date'] = (pd.to_datetime(data['publication_date']) - pd.to_datetime('1970-01-01')) / np.timedelta64(1, 'M') + np.random.normal(0, 1, len(data))\n",
    "data['date'] = data['date'].astype(float)\n",
    "data = data.drop(columns=['publication_date'])\n",
    "\n",
    "# Add noise to duration (std = 20 seconds) to avoid the channel always doing 10:00, ...\n",
    "data['duration'] = data['duration'] + np.random.normal(0, 1, len(data)) * 20\n",
    "\n",
    "# One-hot encoding of the channel, categories and tags, language, or project on a line, or embedding\n",
    "# categorical ⇒ continuous : https://towardsdatascience.com/categorical-embeddings-with-catboost-9f87ceda76a2\n",
    "# the less frequent values are encoded as 'other'\n",
    "\n",
    "# add noise to number of views, likes, ... to avoid overfitting if multiple epochs\n",
    "# data['views'] = data['views'] + np.random.normal(0, 1, len(data)) * 1000\n",
    "# data['like_count'] = data['like_count'] + np.random.normal(0, 1, len(data)) * 50\n",
    "# compute ratios/feature engineering BEFORE adding noise"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
